% !TEX options=--shell-escape
\documentclass[headings=optiontoheadandtoc,listof=totoc,parskip=full]{scrartcl}

\usepackage{amsmath,mathtools}
\usepackage{enumitem}
\usepackage[margin=.75in]{geometry}
\usepackage[headsepline]{scrlayer-scrpage}
\usepackage[USenglish]{babel}
\usepackage{hyperref}
\usepackage{xurl}
\usepackage{graphicx}
\usepackage{float}
\usepackage{subcaption}
\usepackage[newfloat]{minted}
\usepackage{xcolor,tcolorbox}
\usepackage{physics}
\usepackage{needspace}
\usepackage{tikz-cd}
\usepackage[format=hang, justification=justified]{caption}

\usepackage{cleveref} % Needs to be loaded last

\hypersetup{
	linktoc = all,
	pdfborder = {0 0 .5 [ 1 3 ]}
}

\newenvironment{longlisting}{\captionsetup{type=listing}}{}
\SetupFloatingEnvironment{listing}{listname=Code Listings}

\definecolor{lightgray}{gray}{0.95}

\newmintedfile[cppcode]{c++}{
	linenos,
	firstnumber=1,
	tabsize=2,
	bgcolor=lightgray,
	frame=single,
	breaklines,
	%texcomments % Turned off due to the presence of _ characters in many comments
}

\newmintedfile[plotcode]{gnuplot}{
	linenos,
	firstnumber=1,
	tabsize=2,
	bgcolor=lightgray,
	frame=single,
	breaklines,
}

\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

\pagestyle{scrheadings}
\rohead{Novotny \& Page}
\lohead{CS 474 Programming Assignment 1}

\title{Programming Assignment 1}
\subtitle{CS 474\\\url{https://github.com/alexander-novo/CS474-PA1}}
\author{Alexander Novotny\\50\% Work \and Matthew Lyman Page\\50\% Work}

\begin{document}
\maketitle
\tableofcontents

\newpage

\section{Image Sampling}

\subsection{Theory}
Image sampling is one of two key processes during image acquisition and digitization. Intuitively, sampling can be defined as the process whereby a continuous image is transformed such that the 2D locations of an image are represented by a discrete coordinate system. Mathematically this can be defined as a map \[
	m:f(s, t) \rightarrow f(x, y)
\]where $s, t$ are non-negative real values and $x, y$ are non-negative integers. In this formalism an image is viewed as a 2D function, where the domain defines the location of the image and the range defines the possible pixel values of the image.

The quality of a digital image depends heavily on the number of samples taken. An image with more samples will in general appear more alike to the original continuous image, however it will require more memory to store an image as the number of samples increases. If an image is under sampled, then certain artifacts may appear in the newly created digital image and aliasing may occur.

\subsection{Implementation}
In order to implement image sampling, a pgm image was first read into the program using command line arguments, along with the output image location and sub sampling factor. In order to sample the image, image pixels were iterated over using a nested for loop, however, every $n$ pixels were skipped, where $n$ is the sub-sample factor. For every $n$ pixels, its value was stored and a second set of nested for loops were used in order to modify a $k \times k$ window of pixels, such that each pixel in the window became the same value as the sampled image. This process continues until the end of the image is reached. This approach was taken so that the image would maintain the same number of pixels for comparison and visualization purposes. The main data structure used was the image class, used to represent the original image. Each value of the image was modified in place to create the sub-sampled image.

\subsection{Results and Discussion}
The results of the sub-sampling algorithm are showcased using the \texttt{lenna.pgm} and \texttt{peppers.pgm} images. \Cref{fig:sample-result-1} used the \texttt{lenna.pgm} image to demonstrate the effect of sub-sampling. According to the figure, the effects of sub-sampling become prominent immediately, particularly along the edges within the image where aliasing can be seen. Once the image is sub-sampled by a factor of four, the details of the image begin to be obscured. This is especially shown in the features of the woman’s face and hair, where the details become less clear. Lastly, the image sub-sampled by a factor of eight loses nearly all of its finer details, and only the larger, more general features of the image remain identifiable. 

\begin{figure}[ht]
	\centering
	\includegraphics[width=.2\textwidth]{../Images/lenna}
	\includegraphics[width=.2\textwidth]{../out/lenna-2-sampled}
	\includegraphics[width=.2\textwidth]{../out/lenna-4-sampled}
	\includegraphics[width=.2\textwidth]{../out/lenna-8-sampled}
	\caption{A comparison of \texttt{lenna.pgm} with varying sub-sampled images, scaled accordingly (From left to right: 256 x 256, 128 x 128, 64 x 64, 32 x 32).}
	\label{fig:sample-result-1}
\end{figure}

The same sub-sampling process was conducted with the peppers image, which are shown in \cref{fig:sample-result-2}. Similarly to the \texttt{lenna.pgm} image, the image quality begins to degrade after sub-sampling by a factor of two. After sub-sampling by a factor of four, the aliasing on the pepper’s edges becomes more evident and the original texture of the peppers becomes more distorted. Finally, the image sub-sampled by a factor of eight loses most of the small details and it becomes difficult to make out the original image.

\begin{figure}[ht]
	\centering
	\includegraphics[width=.2\textwidth]{../Images/peppers}
	\includegraphics[width=.2\textwidth]{../out/peppers-2-sampled}
	\includegraphics[width=.2\textwidth]{../out/peppers-4-sampled}
	\includegraphics[width=.2\textwidth]{../out/peppers-8-sampled}
	\caption{A comparison of \texttt{peppers.pgm} with varying subsampled images, scaled accordingly (From left to right: 256 x 256, 128 x 128, 64 x 64, 32 x 32).}
	\label{fig:sample-result-2}
\end{figure}

Based on the sampling experiments conducted, it appears that sampling has an immediate effect on the pgm images, with the smoothness of the edges being lost initially, followed by smaller details within the image, and finally the image loses most of its original features. Although details may be lost, sub-sampling may provide an opportunity to reduce the memory requirements of an image at a cost of quality. Further comparisons between sub-sampling and the technique of image quantization will be discussed at the end of the following section.

\section{Image Quantization}

\subsection{Theory}
Image quantization is the second major process when digitizing an image. As opposed to image sampling, which aims to discretize the image coordinates or pixel locations, quantization is responsible for discretizing the pixel values from a continuous value to finite integer values. Using the same model of an image as a 2D function, quantization is equivalent to transforming the output, or range, of the image function $f(x,y)$ from the set of non-negative real values to a finite set of non-negative integer values. Similar to sampling, quantization is required in order to properly store an image on a digital system by limiting the required number of parameters needed to represent an image, thereby saving memory or disk space.

The number of integers used for the pixel values is defined by the quantization level $L$. Typically this value is power of 2, and determines the range of possible pixel values from 0 up to $L-1$. In general, the higher the quantization level is, the higher the quality of the image will be, due to more gray level values being possible at each pixel location. 

\subsection{Implementation}

Image quantization also used command line arguments to read the input image, output image location, and quantization level. After reading the image, each pixel is iterated over and discretized according to the new quantization level. 

The main data structures used in this algorithm include the image class and a vector of new pixel values between 0 and 255. These values were calculated by obtaining a pixel value offset using the equation \[\text{offset} = \frac{256}{L}.\] Therefore, a quantization level of 2 gives an offset of 128. Using this offset, the $i$th pixel value is calculated as $i \cdot \text{offset}$ for $0 \geq i \geq \text{quantization level}$. Each pixel value was converted using \[
	p_{new} = newPixelValues[ \floor{p_{old} / \text{offset}} ]
\] where $newPixelValues$ is a vector of size $L$ containing the new gray level values of the image.

\subsection{Results and Discussion}

The quantization algorithm was performed on the two images \texttt{peppers.pgm} and \texttt{lenna.pgm}, both of whose original quantization level were 256. The results of quantizing \texttt{lenna.pgm} are shown in \cref{fig:quantize-result-1}. According to the figure, there is little noticeable difference from quantizing the image down to 128 and 32 gray level values. However, as seen in the figure, once the quantization level dropped to 8, noticeable differences begin to appear in the shading of the image. At quantization level two, the image essentially becomes a binary image, with much of the shading detail lost.

\begin{figure}[ht]
	\centering
	\includegraphics[width=.15\textwidth]{../Images/lenna}
	\includegraphics[width=.15\textwidth]{../out/lenna-128-quantized}
	\includegraphics[width=.15\textwidth]{../out/lenna-32-quantized}
	\includegraphics[width=.15\textwidth]{../out/lenna-8-quantized}
	\includegraphics[width=.15\textwidth]{../out/lenna-2-quantized}
	\caption{A comparison of \texttt{lenna.pgm} with varying quantization levels (From left to right: L=256, L=128, L=32, L=8, and L=2).}
	\label{fig:quantize-result-1}
\end{figure}

\Cref{fig:quantize-result-2} demonstrates a similar quantization process for the \texttt{pepper.pgm} image. With this image, there are very little noticeable differences for the level 128 and 32 quantized images compared to the original. At quantization level 8, the differences become prominent, especially for the two large peppers featured at the center of the image. Lastly, the level two quantized pepper image on the right resembles a binary image, with minimal detail compared to the other images.

\begin{figure}[ht]
	\centering
	\includegraphics[width=.15\textwidth]{../Images/peppers}
	\includegraphics[width=.15\textwidth]{../out/peppers-128-quantized}
	\includegraphics[width=.15\textwidth]{../out/peppers-32-quantized}
	\includegraphics[width=.15\textwidth]{../out/peppers-8-quantized}
	\includegraphics[width=.15\textwidth]{../out/peppers-2-quantized}
	\caption{A comparison of \texttt{peppers.pgm} with varying quantization levels (From left to right: L=256, L=128, L=32, L=8, and L=2).}
	\label{fig:quantize-result-2}
\end{figure}

Overall, it appears that the effects of image quantization does not degrade an image as much as image sub-sampled. With both images, the effects of image sub-sampled become noticeable even after sub-sapling by a factor of two, whereas in image quantization the effects do not drastically detract from the quality of the image until the quantization level of 8 is used. As a consequence, in the case of memory limitations it would be advisable to first reduce the quantization level of an image rather than sub-sample it, as this would lead to the fewest defects while reducing the memory requirements of an image.

\section{Histogram Equalization}

\subsection{Theory}
\label{sec:equalization-theory}
It is desirable to have high contrast in an image, as it allows you (and a computer vision algorithm) to pick out details more easily. In general, images whose histograms have a uniform distribution tend to have high contrast - especially when compared with images with a central mode (represented by a central ``hump'' in the histogram). To convert a (continuously distributed) random variable $X$ to a uniform distributed random variable $Y$, we simply apply the transformation \[
	Y = F_X(X),
\] where $F_X$ is the CDF (cumulative distribution function) of $X$. As a transformation of the variable $X$, we know then that the PDF (probability density function) of $Y$ is
\begin{align*}
	f_Y(y) &= f_X(F_X^{-1}(y)) \abs{\dv{y} F_X^{-1}(y)},\\
\intertext{and by the inverse function theorem of calculus,}
		&= f_X(F_X^{-1}(y)) \abs{\frac{1}{F_X'(F_X^{-1}(y))}}\\
		&= f_X(F_X^{-1}(y)) \abs{\frac{1}{f_X(F_X^{-1}(y))}}\\
		&= 1,
\end{align*}
so $Y \sim \mathcal U(0, 1)$. Of course, this only applies to continuous random variables, but we hope that a similar behaviour can be observed in discrete random variables. Unfortunately, since all pixels fall into a certain number of ``bins'' in the image's histogram (based on the quantization level of the image), the transform can't decrease the number of pixels in a bin. Instead, it can only spread bins out in the histogram and consolidate multiple bins into one, increasing the number of pixels in a bin. Therefore, if there are noticeable modes in the original image's histogram, there will still be noticeable modes in the equalized histogram. As well, image quality will drop due to the spreading out and consolidating of bins effectively quantizing the image.

Since this behaviour comes from the approximation of continuous distributions by discrete distributions, the better an approximation is, the less noticeable these effects become. Therefore, increasing the quantization level of an image will make the process more effective, causing the output image's histogram to be more like a uniform distribution.

\subsection{Implementation}
\label{sec:equalization-implementation}

An array of integers is used for the image's histogram, which is calculated by looping over the image's pixels and incrementing the bin whose index is given by the pixel's intensity value. Then, the CDF is calculated by iteratively summing over the calculated histogram, using the recurrence relation for discrete CDFs:
\begin{equation}
	\begin{aligned}
		F_X(x) &= \sum_{i = -\infty}^x P(X = x)\\
			&= P(X = x) + \sum_{i = -\infty}^{x - 1} P(X = x)\\
			&= P(X = x) + F_X(x - 1),
	\end{aligned}
\end{equation}
where $P(X = x)$ is the histogram value of the intensity $x$. Since pixel intensities have finitely many values (and therefore a minimum value), $F_X(x - 1) = 0$ for some $x$ (the minimum intensity) and $F_X(x) = P(X = x)$.

The CDF is never converted to its normalized version. Instead, when applying the transformation, each resulting transformed pixel is multiplied by the normalization constant. This is to prevent accumulation of round-off errors until the final integer pixel value is calculated.

Since the calculation of the original histogram and the transformation is embarrassingly parallel, OpenMP is used to parallelize.

The source code for this implementation can be found in \cref{lst:equalize}.

\subsection{Results and Discussion}
\label{sec:equalization-results}

\Cref{fig:equal-result-1} shows the result of applying the algorithm to the image \texttt{boat.pgm}. There is a noticeable difference in contrast - especially in the water, which is much clearer, and the shadows on the sail. However, there is some noise introduced in the sky, and loss of detail on the coast.

\begin{figure}[H]
	\centering
	\includegraphics[width=.35\textwidth]{../Images/boat}
	\includegraphics[width=.35\textwidth]{../out/boat-equal}
	\caption{A comparison of \texttt{boat.pgm} with its equalization (right).}
	\label{fig:equal-result-1}
\end{figure}

\Cref{fig:equal-histogram-1} compares the original histogram of \texttt{boat.pgm} with the histogram of the new equalized image. As discussed in \cref{sec:equalization-theory}, the new histogram is not that of a uniform distribution, but there are some notable improvements over the original histogram. Firstly, the bins concentrated around the various modes have become sparser, so while the modes still exist with the same number of pixels in their bins(as discussed earlier), there are fewer pixels in the region of the bin. As well, a couple of the modes have spread out, making them easier to differentiate between. Finally, the bins in lower regions of the histogram have concentrated so they aren't as low compared to the modes.

\begin{figure}[H]
	\centering\includegraphics[width=.8\linewidth]{../out/boat-histogram-plot}
	\caption{A comparison of histograms of \texttt{boat.pgm} and its equalized version}
	\label{fig:equal-histogram-1}
\end{figure}

\Cref{fig:equal-result-2} shows the result of applying the algorithm to the image \texttt{f\_16.pgm}. There's a drastic increase in contrast in the clouds, but the results around the text on the plane are a mixed bag - the ``U.S. AIR FORCE'' text in the middle of the plane has good increase in contrast, while the ``F-16'' text on the tail has a decrease in contrast. As well, there is loss of detail on the mountains and the aberration along the left and lower rims of the image.

\begin{figure}[H]
	\centering
	\includegraphics[width=.35\textwidth]{../Images/f_16}
	\includegraphics[width=.35\textwidth]{../out/f_16-equal}
	\caption{A comparison of \texttt{f\_16.pgm} with its equalization (right).}
	\label{fig:equal-result-2}
\end{figure}

\Cref{fig:equal-histogram-2} compares the original histogram of \texttt{f\_16.pgm} with the histogram of the new equalized image. The sparseness of bins and consolidation of bins is more apparent than in the previous example, especially around the mode of the image. This probably accounts for the loss of detail in the image, since most of the notable loss of detail happened in brighter regions of the image. These regions all got placed into the same bin, causing them to lose contrast and detail.

\begin{figure}[H]
	\centering\includegraphics[width=.8\linewidth]{../out/f_16-histogram-plot}
	\caption{A comparison of histograms of \texttt{f\_16.pgm} and its equalized version}
	\label{fig:equal-histogram-2}
\end{figure}

The source code for generating these histogram comparison figures can be found in \cref{lst:histogram-plot-double}.

\section{Histogram Specification}

\subsection{Theory}
As demonstrated in \cref{sec:equalization-results}, we can transform images to have a similar distribution of pixel intensities as a uniform distribution by using the CDF of the image. Since CDFs are monotonically increasing, the pre-image of a single point is always a continuous interval, and when the CDF is strictly increasing (as is usually the case), the pre-image of a single point is also a single point. In this way, we can naturally define an ``inverse'' CDF
\begin{equation}
	Q_X(x) = \inf F_X^{-1}(\{x\}), \label{eq:quantile-func}
\end{equation}
known as the ``quantile'' function. Note that for discrete distributions, the infimum is equal to the minimum, and is chosen because because CDFs are right-continuous (so in a discrete distribution, the minimum is always a possible value). Using the quantile function, we can transform a uniform distribution back to the original distribution. In this way, for two distributions $X$ and $Y$, $F_X$ transforms $X$ to a uniform distribution and $Q_Y$ transforms a uniform distribution back to $Y$, so $Q_Y \circ F_X$ transforms $X$ to $Y$, demonstrated in  \cref{fig:specification-cd}.

\begin{figure}[H]
	\centering
	\begin{tikzcd}
		X \ar[rd, "F_X" description] \ar[rr, bend left, shift left, "Q_Y \circ F_X"] & & Y \ar[ld, bend right, shift right, "F_Y" description]\\
		& \mathcal U \ar[ru, bend right, shift right, "Q_Y" description]
	\end{tikzcd}
	\caption{A commutative diagram showing how to map from one distribution to another using their CDFs.}
	\label{fig:specification-cd}
\end{figure}

In this way, we can perform an image transformation similar to histogram equalization, but with a supplied distribution instead of just a uniform distribution. This can be used for a similar effect as histogram equalization, but with a handpicked distribution to help avoid detail loss like in histogram equalization.\par

Similarly to histogram equalization, the math isn't exact for discrete distributions, but we can think of discrete distributions as approximations of continuous distributions. There are similar problems with this approximation as with the one made for equalization, but these problems can be lessened with increased quantization levels.

\subsection{Implementation}

The CDFs of the input image and input histogram are calculated in the same way as detailed in \cref{sec:equalization-implementation}. Then, each pixel's intensity is normalized with the input image's normalization constant and unnormalized with the input histogram's normalization constant. This step can be avoided if the images share a normalization constant - notably, when they are the same size and quantization levels. The quantile function (\cref{eq:quantile-func}) is then calculated on the unnormalized value using a binary search on the input histogram's CDF. This is done, rather than calculating the quantile function for every possible value, to save memory and because a binary search can take advantage of the sorted nature of the calculated CDF.

The source code for this implementation can be found in \cref{lst:specify}.

\subsection{Results and Discussion}
\label{sec:specification-results}

\Cref{fig:specify-result-1} shows the results of specifying \texttt{boat.pgm} to \texttt{sf.pgm}'s histogram. Since \texttt{sf.pgm} has much less contrast than \texttt{boat.pgm} and fewer extremely dark/light pixels, there is a huge loss of detail.

\begin{figure}[H]
	\centering
	\includegraphics[width=.35\textwidth]{../Images/boat}
	\includegraphics[width=.35\textwidth]{../out/boat-sf-specify}
	\caption{A comparison of \texttt{boat.pgm} with its specification to \texttt{sf.pgm} (right).}
	\label{fig:specify-result-1}
\end{figure}

\Cref{fig:specify-histogram-1} compares the histograms of \texttt{boat.pgm}, \texttt{sf.pgm}, and the specified output above. As can be seen, the algorithm does a much better job at matching the given histogram than matching a uniform distribution. From just a cursory glance at the comparison, it is hard to tell the output image's histogram apart from the input histogram. This is because the input histogram occupies a narrower band of intensities and has higher peaks than the input image's histogram, allowing the algorithm to consolidate bins effectively. This can be demonstrated by the areas where the algorithm fails to transform the histogram well - near the right side of the histogram - since this region of the input image's histogram is much larger than the input histogram. The reverse transformation would likely not be nearly as successful.

\begin{figure}[H]
	\centering\includegraphics[width=.8\linewidth]{../out/boat-sf-specified-plot}
	\caption{A comparison of histograms of \texttt{boat.pgm}, \texttt{sf.pgm}, and the specified output as seen in \cref{fig:specify-result-1}.}
	\label{fig:specify-histogram-1}
\end{figure}

\Cref{fig:specify-result-2} shows the result of specifying \texttt{f\_16.pgm} to \texttt{peppers.pgm}'s histogram. Since \texttt{peppers.pgm} has a large number of of purely black pixels, a similar amount of pixels in \texttt{f\_16.pgm} are converted to be purely black and there is a resulting large amount of detail loss - especially around darker regions.

\begin{figure}[H]
	\centering
	\includegraphics[width=.35\textwidth]{../Images/f_16}
	\includegraphics[width=.35\textwidth]{../out/f_16-peppers-specify}
	\caption{A comparison of \texttt{f\_16.pgm} with its specification to \texttt{peppers.pgm} (right).}
	\label{fig:specify-result-2}
\end{figure}

\Cref{fig:specify-histogram-2} compares the histograms of \texttt{f\_16.pgm}, \texttt{peppers.pgm}, and the specified output above. This gives a better look at the strengths and weaknesses of the algorithm - wherever the input image's histogram is below the input histogram (such as to the left), the algorithm succeeds in replicating the input histogram. In other regions (such as to the middle and right), the algorithm can only space out the bins to make the average density in a region similar.

\begin{figure}[H]
	\centering\includegraphics[width=.8\linewidth]{../out/f_16-peppers-specified-plot}
	\caption{A comparison of histograms of \texttt{f\_16.pgm}, \texttt{peppers.pgm}, and the specified output as seen in \cref{fig:specify-result-2}.}
	\label{fig:specify-histogram-2}
\end{figure}

\clearpage
\listoflistings

Source code can also be found on the project's GitHub page: \url{https://github.com/alexander-novo/CS474-PA1}.

\begin{longlisting}
	\caption{Header file for the common \texttt{Image} class.}
	\cppcode{../Common/image.h}
\end{longlisting}

\begin{longlisting}
	\caption{Implementation file for the common \texttt{Image} class.}
	\cppcode{../Common/image.cpp}
\end{longlisting}

\begin{longlisting}
	\caption{Implementation file for the \texttt{Histogram} supporting library.}
	\cppcode{../Common/histogram_tools.cpp}
\end{longlisting}

\begin{longlisting}
	\caption{Implementation file for the \texttt{sample} program.}
	\cppcode{../Q1-Sampling/main.cpp}
\end{longlisting}

\begin{longlisting}
	\caption{Implementation file for the \texttt{quantize} program.}
	\cppcode{../Q2-Quantization/main.cpp}
\end{longlisting}

\begin{longlisting}
	\caption{Implementation file for the \texttt{equalize} program.}
	\label{lst:equalize}
	\cppcode{../Q3-Equalization/main.cpp}
\end{longlisting}

\begin{longlisting}
	\caption{Implementation file for the \texttt{specify} program.}
	\label{lst:specify}
	\cppcode{../Q4-Specification/main.cpp}
\end{longlisting}

\begin{listing}[H]
	\caption[\texttt{gnuplot} plotting file for generating two-histogram comparison plots.]{\texttt{gnuplot} plotting file for generating two-histogram comparison plots.\\Used for generating comparison plots in \cref{sec:equalization-results}.}
	\label{lst:histogram-plot-double}
	\plotcode{../Q3-Equalization/plot-histograms.plt}
\end{listing}

\begin{listing}[H]
	\caption[\texttt{gnuplot} plotting file for generating three-histogram comparison plots.]{\texttt{gnuplot} plotting file for generating three-histogram comparison plots.\\Used for generating comparison plots in \cref{sec:specification-results}.}
	\plotcode{../Q4-Specification/plot-histograms.plt}
\end{listing}

\end{document}